# 参考
作者：半兽人

链接：http://orchome.com/5

### kakfa的优势
1. 构建实时的流数据管道，可靠地获取系统和应用程序之间的数据。
1. 构建实时流的应用程序，对数据流进行转换或反应。
###  核心API
* 应用程序使用 Producer API 发布消息到1个或多个topic（主题）。
* 应用程序使用 Consumer API 来订阅一个或多个topic，并处理产生的消息。
* 应用程序使用 Streams API 充当一个流处理器，从1个或多个topic消费输入流，并生产一个输出流到1个或多个输出topic，有效地将输入流转换到输出流。
* Connector API允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。例如，一个关系数据库的连接器可捕获每一个变化。
### 基本术语
* Topic

    Kafka将消息种子(Feed)分门别类，每一类的消息称之为一个主题(Topic).

* Producer

    发布消息的对象称之为主题生产者(Kafka topic producer)

* Consumer

    订阅消息并处理发布的消息的种子的对象称之为主题消费者(consumers)

* Broker

    已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。

### partition(分区)
每一个`Topic`可以有多个分区,每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量(**offset**)，**在每个分区中此偏移量都是唯一的**。

采用分区的目的:
* 可以处理更多的数据,不受单台服务器限制.
* 分区可以作为并行处理的单元.


每个分区有一个leader，零或多个follower。Leader处理此分区的所有的读写请求，而follower被动的复制数据。如果leader宕机，其它的一个follower会被推举为新的leader。 一台服务器可能同时是一个分区的leader，另一个分区的follower。 这样可以平衡负载，避免所有的请求都只让一台或者某几台服务器处理。

### 消费者
消费信息模型分为:队列和发布-订阅模式,消费者可以分组,每一个`Topic`的分区的消息发送给所有组的每个组的一个消费者,对于所有组来说消息
是发布-订阅模式,对于同一个组中的消费者来说,是队列模式.

**相同的消费者组中不能有比分区更多的消费者，否则多出的消费者一直处于空等待，不会收到消息**
**如果想要顺序的处理一个Topic的消息,只提供一个分区.**
### kafka可以保证的事
* 消息按照发送的顺序储存在指定的分区.
* 消费者收到的消息顺序也是如此.
* 一个Topic的复制因子为N,那么可以允许N-1服务器宕机而不丢失消息

### 数据持久和效率
高度依赖文件系统来储存和缓存信息.

##### 在多程序对文件的读写操作的情况下,会产生两个常见的问题:
* 大量小的I/O操作
    client和server交互,server自身的持久化操作,都会产生小的IO操作
* 过度的字节复制
    产生于数据从文件传输到Socket中的过程,一般的过程为:
    1. 操作系统将数据从磁盘读入到内核空间的页缓存
    1. 应用程序将数据从内核空间读入到用户空间缓存中
    1. 应用程序将数据写回到内核空间到socket缓存中
    1. 操作系统将数据从socket缓冲区复制到网卡缓冲区，以便将数据经网络发出
    
四次拷贝,两次系统调用.

##### kafka避免上述问题的相应方法:
* 将消息聚合在一起,减小网络请求的往返.而不是一次发送单个信息.
* 减少过度字节复制:
    * 生产者,borker,消费者采用相同的消息二进制格式,这样可以自由传输,而不用转换.
    * 使用linux的`sendfile`系统,允许操作系统将数据直接从页缓存发送到网络上。所以在这个优化的路径中，只有最后一步将数据拷贝到网卡缓存中是需要的
    * 多个消费者的情况下,数据复制到页缓存上,重复使用.

这种页缓存和sendfile组合，意味着Kafka集群的消费者大多数都完全从缓存消费消息，而磁盘没有任何读取活动

有关java的Sendfile和零拷贝,参阅[这里](http://www.ibm.com/developerworks/linux/library/j-zerocopy)

##### 批量压缩
通过批压缩消息,kafka支持`GZIP`和`Snappy`压缩协议.
### 消息传递保证
* 最多一次 --- 消息可能丢失，但绝不会重发。
* 至少一次 --- 消息绝不会丢失，但有可能重新发送。
* 正好一次 --- 这是人们真正想要的，每个消息传递一次且仅一次。

当发布一条消息时，该消息 “committed（承诺）” 到了日志，一旦发布的消息是”承诺“的，只要副本分区写入了此消息的一个broker仍然"活着”，它就不会丢失。

在0.11.0.0之前，如果一个生产者没有收到消息提交的响应，那么只能重新发送消息。 这提供了至少一次传递语义，因为如果原始请求实际上已成功，则在重新发送期间再次将消息写入到日志中。
自0.11.0.0起，Kafka生产者支持幂等传递选项，保证重新发送不会导致日志中重复。 broker为每个生产者分配一个ID，并通过生产者发送的序列号为每个消息进行去重。从0.11.0.0开始，生产者支持使用类似事务的语义将消息发送到多个topic分区的能力：即所有消息都被成功写入，或者没有。
这个主要用于Kafka topic之间“正好一次“处理

并不是所有的情况都需要这么强力的保障，对于延迟敏感的，我们允许生产者指定它想要的耐用性水平。如生产者可以指定它获取需等待10毫秒量级上的响应。生产者也可以指定异步发送，或只等待leader（不需要副本的响应）有响应，


如果消费者故障，我们希望这个topic分区被另一个进程接管，新进程需要选择一个合适的位置开始处理。我们假设消费者读取了一些消息，几种选项用于处理消息和更新它的位置:

1. 读取消息，然后在日志中保存它的位置，最后处理消息。在这种情况下，有可能消费者保存了位置之后，但是处理消息输出之前崩溃了。在这种情况下，接管处理的进程会在已保存的位置开始，即使该位置之前有几个消息尚未处理。这对应于“最多一次” ，在消费者处理失败消息的情况下，不进行处理。
1. 读取消息，处理消息，最后保存消息的位置。在这种情况下，可能消费进程处理消息之后，但保存它的位置之前崩溃了。在这种情况下，当新的进程接管了它，这将接收已经被处理的前几个消息。这就符合了“至少一次”的语义。在多数情况下消息有一个主键，以便更新幂等（其任意多次执行所产生的影响均与一次执行的影响相同）。
1. 那么什么是“正好一次”语义（也就是你真正想要的东西）? 当从Kafka主题消费并生产到另一个topic时（例如Kafka Stream），我们可以利用之前提到0.11.0.0中的生产者新事物功能。消费者的位置作为消息存储到topic中，因此我们可以与接收处理后的数据的输出topic使用相同的事务写入offset到Kafka。如果事物中断，则消费者的位置将恢复到老的值，根据其”隔离级别“，其他消费者将不会看到输出topic的生成数据，在默认的”读取未提交“隔离级别中，所有消息对消费者都是可见的，即使是被中断的事务的消息。但是在”读取提交“中，消费者将只从已提交的事物中返回消息。


kafka默认是保证“至少一次”传递，并允许用户通过禁止生产者重试和处理一批消息前提交它的偏移量来实现 “最多一次”传递。而“正好一次”传递需要与目标存储系统合作，但kafka提供了偏移量，所以实现这个很简单。